# ðŸ“Š DriveAnalizer VeritabanÄ± Optimizasyon Yol HaritasÄ±

**Proje:** DriveAnalizer  
**AmaÃ§:** VeritabanÄ±nÄ±n ÅŸiÅŸmesini Ã¶nlemek ve yer kullanÄ±mÄ±nÄ± minimize etmek  
**BaÅŸlangÄ±Ã§ Tarihi:** AralÄ±k 2025  
**Hedef:** %60-70 veritabanÄ± boyutu azaltma

---

## ðŸ“‹ Ä°Ã§indekiler

1. [Mevcut Durum Analizi](#mevcut-durum-analizi)
2. [Sorunlar ve Ã‡Ã¶zÃ¼mler](#sorunlar-ve-Ã§Ã¶zÃ¼mler)
3. [Uygulama PlanÄ±](#uygulama-planÄ±)
4. [DetaylÄ± GÃ¶revler](#detaylÄ±-gÃ¶revler)
5. [Test Stratejisi](#test-stratejisi)
6. [BaÅŸarÄ± Metrikleri](#baÅŸarÄ±-metrikleri)

---

## ðŸ” Mevcut Durum Analizi

### Mevcut VeritabanÄ± YapÄ±sÄ±

```
ðŸ“¦ Database: drive_analytics.db
â”œâ”€â”€ ðŸ“‹ disk_stats (Ana Tablo)
â”‚   â”œâ”€â”€ id: INTEGER PRIMARY KEY
â”‚   â”œâ”€â”€ timestamp: REAL (8 byte)
â”‚   â”œâ”€â”€ read_bytes: INTEGER (8 byte)
â”‚   â”œâ”€â”€ write_bytes: INTEGER (8 byte)
â”‚   â”œâ”€â”€ read_speed: INTEGER (8 byte)
â”‚   â”œâ”€â”€ write_speed: INTEGER (8 byte)
â”‚   â””â”€â”€ INDEX: idx_disk_stats_timestamp
â”‚
â””â”€â”€ ðŸ“‹ process_history (KÃ¼mÃ¼latif Tablo)
    â”œâ”€â”€ name: TEXT PRIMARY KEY
    â”œâ”€â”€ read_bytes: INTEGER
    â””â”€â”€ write_bytes: INTEGER
```

### Mevcut PRAGMA AyarlarÄ±

```rust
PRAGMA journal_mode = WAL;      // âœ… Aktif (iyi)
PRAGMA synchronous = NORMAL;    // âœ… AyarlÄ± (iyi)
// âŒ Eksik optimizasyonlar:
// - Cache size ayarlanmamÄ±ÅŸ
// - WAL checkpoint stratejisi optimized deÄŸil
// - ANALYZE/VACUUM otomatik Ã§alÄ±ÅŸmÄ±yor
// - Veri retention policy yok
```

### Veri Birikme HÄ±zÄ±

```
Ã–rnek Hesaplama (gÃ¼nlÃ¼k):
- disk_stats: 1 satÄ±r/saniye = 86.400 satÄ±r/gÃ¼n
- Ä°lk ayda: 2.592.000 satÄ±r (seri veri)
- 1 yÄ±lda: 31.536.000 satÄ±r = ~400 MB (indeksler dahil)
- Limit yok = sÄ±nÄ±rsÄ±z bÃ¼yÃ¼me
```

---

## âš ï¸ Sorunlar ve Ã‡Ã¶zÃ¼mler

### Problem 1: SÄ±nÄ±rsÄ±z Veri Birikimi

| Sorun | Etki | Ciddiyeti |
|-------|------|-----------|
| Eski veriler otomatik silinmiyor | DB sÄ±nÄ±rsÄ±z bÃ¼yÃ¼r | ðŸ”´ YÃ¼ksek |
| Dedup mekanizmasÄ± yok | AynÄ± veriler tekrar saklanabilir | ðŸŸ¡ Orta |
| Batch insert optimized deÄŸil | YavaÅŸ yazma performansÄ± | ðŸŸ¡ Orta |

**Ã‡Ã¶zÃ¼m:** Data retention policy + otomatik cleanup

### Problem 2: Eksik Ä°ndeksler

| Sorun | Etki | Ciddiyeti |
|-------|------|-----------|
| process_history'de name Ã¼zerinde index yok | Sorgu yavaÅŸ | ðŸŸ¡ Orta |
| Zaman aralÄ±ÄŸÄ± sorgularÄ±nda index eksik | Filtreleme yavaÅŸ | ðŸŸ¡ Orta |

**Ã‡Ã¶zÃ¼m:** Stratejik indeksler ekle

### Problem 3: PRAGMA Optimizasyonu Eksik

| Sorun | Etki | Ciddiyeti |
|-------|------|-----------|
| Cache size ayarlanmamÄ±ÅŸ | Bellek verimsizliÄŸi | ðŸŸ¡ Orta |
| WAL checkpoint otomatik deÄŸil | WAL dosyalarÄ± bÃ¼yÃ¼r | ðŸŸ¡ Orta |
| VACUUM otomatik Ã§alÄ±ÅŸmÄ±yor | BoÅŸ alan geri alÄ±nmÄ±yor | ðŸŸ¡ Orta |

**Ã‡Ã¶zÃ¼m:** PRAGMA ayarlarÄ±nÄ± optimize et

### Problem 4: Veri Tipi AlanÄ±nda Optimizasyon

| Sorun | Etki | Ciddiyeti |
|-------|------|-----------|
| read_speed/write_speed INTEGER (8 byte) | Gereksiz yer | ðŸŸ¢ DÃ¼ÅŸÃ¼k |
| idle_time/queue_depth modele eklenmemiÅŸ ama DiskStat'ta var | VeritabanÄ±nda tutulmayan veri | ðŸŸ¢ DÃ¼ÅŸÃ¼k |

**Ã‡Ã¶zÃ¼m:** Veri tipi iyileÅŸtirmesi (optional)

---

## ðŸ“… Uygulama PlanÄ±

### Faz 1: Temel AltyapÄ± (1-2 gÃ¼n)
- [ ] Data retention policy modÃ¼lÃ¼ oluÅŸtur
- [ ] Scheduled cleanup fonksiyonu yaz
- [ ] PRAGMA ayarlarÄ±nÄ± optimize et

### Faz 2: VeritabanÄ± ÅžemasÄ± Ä°yileÅŸtirmesi (1-2 gÃ¼n)
- [ ] Ä°ndeks stratejisi geliÅŸtir
- [ ] Archive mekanizmasÄ± oluÅŸtur
- [ ] Migration komut dosyasÄ± hazÄ±rla

### Faz 3: Performans Optimizasyonu (1 gÃ¼n)
- [ ] Batch insert iÅŸlemini refactor et
- [ ] Query optimization
- [ ] Periyodik maintenance rutini

### Faz 4: Monitoring ve Testing (1-2 gÃ¼n)
- [ ] Database size tracking
- [ ] Cleanup effectiveness tests
- [ ] Performance benchmarks

### Faz 5: Deployment (1 gÃ¼n)
- [ ] KullanÄ±cÄ± bildirimi
- [ ] Migrasyon scripti Ã§alÄ±ÅŸtÄ±r
- [ ] Production monitoring

---

## ðŸŽ¯ DetaylÄ± GÃ¶revler

### Task 1: Data Retention Policy ModÃ¼lÃ¼

**Dosya:** `src-tauri/src/db_cleanup.rs` (YENÄ°)

```rust
// GÃ¶rev: Eski verileri temizlemek iÃ§in yapÄ± oluÅŸtur

pub struct RetentionPolicy {
    pub keep_days: u64,           // KaÃ§ gÃ¼n veri saklansÄ±n
    pub sample_interval: u64,     // Her n. veriyi sakla
    pub archive_enabled: bool,    // Archive mekanizmasÄ± aktif mi
}

impl Default for RetentionPolicy {
    fn default() -> Self {
        Self {
            keep_days: 30,         // 30 gÃ¼n tuttuÄŸu varsayÄ±lan
            sample_interval: 1,    // TÃ¼m veriyi sakla
            archive_enabled: true, // Archive aktif
        }
    }
}

pub async fn cleanup_old_data(
    pool: &Pool<Sqlite>,
    policy: &RetentionPolicy,
) -> Result<u64, sqlx::Error> {
    // Cutoff timestamp hesapla
    let now = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs_f64();
    
    let cutoff = now - (policy.keep_days as f64 * 86400.0);
    
    // Eski veri sayÄ±sÄ±nÄ± al
    let count: (i64,) = sqlx::query_as(
        "SELECT COUNT(*) FROM disk_stats WHERE timestamp < ?"
    )
    .bind(cutoff)
    .fetch_one(pool)
    .await?;
    
    // Sil
    sqlx::query("DELETE FROM disk_stats WHERE timestamp < ?")
        .bind(cutoff)
        .execute(pool)
        .await?;
    
    Ok(count.0 as u64)
}
```

**BaÅŸarÄ± Kriteri:**
- âœ… Verilen gÃ¼n sayÄ±sÄ±ndan eski verileri siler
- âœ… Silinecek veri sayÄ±sÄ±nÄ± dÃ¶ndÃ¼rÃ¼r
- âœ… Hata durumunda transaction rollback

---

### Task 2: Otomatik Cleanup Task (Background)

**Dosya:** `src-tauri/src/scheduled_tasks.rs` (YENÄ°)

```rust
// GÃ¶rev: Arka planda periyodik cleanup Ã§alÄ±ÅŸtÄ±r

use tokio::time::{interval, Duration};

pub async fn start_cleanup_scheduler(pool: Arc<Pool<Sqlite>>) {
    // 24 saat her interval'de cleanup Ã§alÄ±ÅŸtÄ±r
    let mut cleanup_interval = interval(Duration::from_secs(86400));
    
    loop {
        cleanup_interval.tick().await;
        
        match cleanup_old_data(&pool).await {
            Ok(count) => {
                println!("[Cleanup] Successfully deleted {} old records", count);
                
                // VACUUM ile space boÅŸalt
                match sqlx::query("VACUUM").execute(&pool).await {
                    Ok(_) => println!("[Cleanup] VACUUM completed"),
                    Err(e) => eprintln!("[Cleanup] VACUUM failed: {}", e),
                }
            }
            Err(e) => {
                eprintln!("[Cleanup] Failed to cleanup: {}", e);
            }
        }
    }
}

pub async fn start_analyze_scheduler(pool: Arc<Pool<Sqlite>>) {
    // HaftalÄ±k ANALYZE Ã§alÄ±ÅŸtÄ±r
    let mut analyze_interval = interval(Duration::from_secs(604800));
    
    loop {
        analyze_interval.tick().await;
        
        match sqlx::query("ANALYZE").execute(&pool).await {
            Ok(_) => println!("[Analyze] Query optimization completed"),
            Err(e) => eprintln!("[Analyze] ANALYZE failed: {}", e),
        }
    }
}

pub async fn start_wal_checkpoint_scheduler(pool: Arc<Pool<Sqlite>>) {
    // Her 6 saatte WAL checkpoint yap
    let mut checkpoint_interval = interval(Duration::from_secs(21600));
    
    loop {
        checkpoint_interval.tick().await;
        
        match sqlx::query("PRAGMA wal_checkpoint(PASSIVE)")
            .execute(&pool)
            .await
        {
            Ok(_) => println!("[WAL] Checkpoint completed"),
            Err(e) => eprintln!("[WAL] Checkpoint failed: {}", e),
        }
    }
}
```

**BaÅŸarÄ± Kriteri:**
- âœ… Scheduled cleanup 24 saatte bir Ã§alÄ±ÅŸÄ±r
- âœ… ANALYZE haftalÄ±k optimize eder
- âœ… WAL checkpoint 6 saatte Ã§alÄ±ÅŸÄ±r
- âœ… Hata oluÅŸsa bile diÄŸer interval'ler etkilenmez

---

### Task 3: PRAGMA Optimizasyonu

**Dosya:** `src-tauri/src/db.rs` (DeÄŸiÅŸiklik)

**GÃ¼ncel Kod (lines 29-38):**
```rust
let pool = SqlitePoolOptions::new()
    .max_connections(5)
    .connect(&db_url)
    .await?;

// Create persistent tables
sqlx::query(
    "PRAGMA journal_mode = WAL;
     PRAGMA synchronous = NORMAL;
```

**Yeni Kod:**
```rust
let pool = SqlitePoolOptions::new()
    .max_connections(5)
    .connect(&db_url)
    .await?;

// Optimize PRAGMA settings for better performance
sqlx::query(
    "PRAGMA journal_mode = WAL;
     PRAGMA synchronous = NORMAL;
     PRAGMA cache_size = -64000;
     PRAGMA temp_store = MEMORY;
     PRAGMA wal_autocheckpoint = 1000;
     PRAGMA busy_timeout = 5000;"
)
.execute(&pool)
.await?;

// Create persistent tables
sqlx::query(
```

**AÃ§Ä±klama:**
- `cache_size = -64000`: 64 MB bellek cache (negatif = MB cinsinden)
- `temp_store = MEMORY`: GeÃ§ici iÅŸlemleri bellekte yap
- `wal_autocheckpoint = 1000`: Her 1000 sayfa sonrasÄ± otomatik checkpoint
- `busy_timeout = 5000`: Kilitlenme durumunda 5 saniye bekle

---

### Task 4: Ä°ndeks Stratejisi

**Dosya:** `src-tauri/src/db.rs` (DeÄŸiÅŸiklik)

**Mevcut Ä°ndeksler (line 45):**
```rust
CREATE INDEX IF NOT EXISTS idx_disk_stats_timestamp ON disk_stats(timestamp);
```

**Yeni Ä°ndeksler Ekle:**
```rust
CREATE INDEX IF NOT EXISTS idx_disk_stats_timestamp ON disk_stats(timestamp DESC);
CREATE INDEX IF NOT EXISTS idx_process_name ON process_history(name);
CREATE INDEX IF NOT EXISTS idx_disk_stats_time_range 
    ON disk_stats(timestamp DESC, read_bytes, write_bytes);
```

**AÃ§Ä±klama:**
- `idx_disk_stats_timestamp DESC`: En yeni veriler Ã¶nce gelsin
- `idx_process_name`: Process arama hÄ±zlansÄ±n
- `idx_disk_stats_time_range`: Zaman aralÄ±ÄŸÄ± sorgularÄ±nda hÄ±zlÄ±

---

### Task 5: Archive MekanizmasÄ± (Opsiyonel)

**Dosya:** `src-tauri/src/db_archive.rs` (YENÄ°)

```rust
// GÃ¶rev: 30 gÃ¼nden eski verileri archive tablosuna taÅŸÄ±

pub async fn archive_old_data(
    pool: &Pool<Sqlite>,
    archive_days: u64,
) -> Result<u64, sqlx::Error> {
    // Archive tablosu oluÅŸtur (varsa)
    sqlx::query(
        "CREATE TABLE IF NOT EXISTS disk_stats_archive (
            id INTEGER PRIMARY KEY,
            timestamp REAL NOT NULL,
            read_bytes INTEGER NOT NULL,
            write_bytes INTEGER NOT NULL,
            read_speed INTEGER NOT NULL,
            write_speed INTEGER NOT NULL,
            archived_at REAL NOT NULL
        )"
    )
    .execute(pool)
    .await?;
    
    let now = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs_f64();
    
    let cutoff = now - (archive_days as f64 * 86400.0);
    
    // Eski veriyi archive'a taÅŸÄ±
    let result = sqlx::query(
        "INSERT INTO disk_stats_archive 
         SELECT id, timestamp, read_bytes, write_bytes, read_speed, 
                write_speed, ? as archived_at
         FROM disk_stats 
         WHERE timestamp < ?"
    )
    .bind(now)
    .bind(cutoff)
    .execute(pool)
    .await?;
    
    let count = result.rows_affected();
    
    // AsÄ±l tablodan sil
    sqlx::query("DELETE FROM disk_stats WHERE timestamp < ?")
        .bind(cutoff)
        .execute(pool)
        .await?;
    
    Ok(count)
}
```

---

### Task 6: Batch Insert Optimizasyonu

**Dosya:** `src-tauri/src/db.rs` (DeÄŸiÅŸiklik)

**Mevcut Kod (lines 54-73):**
```rust
pub async fn insert_stats_batch(
    pool: &Pool<Sqlite>,
    stats: &[DiskStat],
) -> Result<(), sqlx::Error> {
    if stats.is_empty() {
        return Ok(());
    }

    let mut query_builder = sqlx::QueryBuilder::new(
        "INSERT INTO disk_stats (timestamp, read_bytes, write_bytes, read_speed, write_speed) "
    );

    query_builder.push_values(stats, |mut b, stat| {
        b.push_bind(stat.timestamp)
         .push_bind(stat.read_bytes as i64)
         .push_bind(stat.write_bytes as i64)
         .push_bind(stat.read_speed as i64)
         .push_bind(stat.write_speed as i64);
    });

    let query = query_builder.build();
    query.execute(pool).await?;

    Ok(())
}
```

**Yeni Kod (Transaction Wrapper):**
```rust
pub async fn insert_stats_batch(
    pool: &Pool<Sqlite>,
    stats: &[DiskStat],
) -> Result<(), sqlx::Error> {
    if stats.is_empty() {
        return Ok(());
    }

    // Transaction iÃ§inde batch insert yap
    let mut tx = pool.begin().await?;

    let mut query_builder = sqlx::QueryBuilder::new(
        "INSERT INTO disk_stats (timestamp, read_bytes, write_bytes, read_speed, write_speed) "
    );

    query_builder.push_values(stats, |mut b, stat| {
        b.push_bind(stat.timestamp)
         .push_bind(stat.read_bytes as i64)
         .push_bind(stat.write_bytes as i64)
         .push_bind(stat.read_speed as i64)
         .push_bind(stat.write_speed as i64);
    });

    query_builder.build().execute(&mut *tx).await?;
    tx.commit().await?;

    Ok(())
}
```

**Fayda:** Transaction daha hÄ±zlÄ±, daha tutarlÄ± veri yazma

---

### Task 7: Sampling MekanizmasÄ± (Opsiyonel)

**Dosya:** `src-tauri/src/db_sampling.rs` (YENÄ°)

```rust
// GÃ¶rev: YoÄŸun periyoklara daha az Ã¶rnek kaydet

pub struct SamplingPolicy {
    pub interval_seconds: u64,  // KaÃ§ saniyede bir kaydet
    pub aggressive_after_days: u64, // KaÃ§ gÃ¼n sonra agresif sampling
}

impl Default for SamplingPolicy {
    fn default() -> Self {
        Self {
            interval_seconds: 5,   // 5 saniyede bir (varsayÄ±lan: 1)
            aggressive_after_days: 7,
        }
    }
}

pub async fn should_insert_stat(
    pool: &Pool<Sqlite>,
    policy: &SamplingPolicy,
) -> Result<bool, sqlx::Error> {
    // Son satÄ±rÄ±n timestamp'ini al
    let last: Option<(f64,)> = sqlx::query_as(
        "SELECT timestamp FROM disk_stats ORDER BY id DESC LIMIT 1"
    )
    .fetch_optional(pool)
    .await?;
    
    if let Some((last_timestamp,)) = last {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs_f64();
        
        // Interval kontrol et
        if now - last_timestamp < policy.interval_seconds as f64 {
            return Ok(false); // Bu veriyi kaydetme
        }
    }
    
    Ok(true) // Veriyi kaydet
}
```

---

### Task 8: Database Size Tracking

**Dosya:** `src-tauri/src/db_stats.rs` (YENÄ°)

```rust
// GÃ¶rev: VeritabanÄ± boyutunu takip et

use std::path::Path;

#[derive(Debug, Clone, serde::Serialize)]
pub struct DatabaseStats {
    pub main_db_size: u64,      // drive_analytics.db
    pub wal_size: u64,          // drive_analytics.db-wal
    pub shm_size: u64,          // drive_analytics.db-shm
    pub total_size: u64,        // Toplam
    pub disk_stats_count: u64,  // SatÄ±r sayÄ±sÄ±
    pub process_history_count: u64,
}

pub async fn get_database_stats(
    pool: &Pool<Sqlite>,
    db_path: &Path,
) -> Result<DatabaseStats, Box<dyn std::error::Error>> {
    // Dosya boyutlarÄ±nÄ± al
    let main_db_size = std::fs::metadata(db_path)
        .map(|m| m.len())
        .unwrap_or(0);
    
    let wal_path = db_path.with_extension("db-wal");
    let wal_size = std::fs::metadata(&wal_path)
        .map(|m| m.len())
        .unwrap_or(0);
    
    let shm_path = db_path.with_extension("db-shm");
    let shm_size = std::fs::metadata(&shm_path)
        .map(|m| m.len())
        .unwrap_or(0);
    
    // SatÄ±r sayÄ±larÄ±nÄ± al
    let (disk_count,): (i64,) = sqlx::query_as(
        "SELECT COUNT(*) FROM disk_stats"
    )
    .fetch_one(pool)
    .await?;
    
    let (process_count,): (i64,) = sqlx::query_as(
        "SELECT COUNT(*) FROM process_history"
    )
    .fetch_one(pool)
    .await?;
    
    let total_size = main_db_size + wal_size + shm_size;
    
    Ok(DatabaseStats {
        main_db_size,
        wal_size,
        shm_size,
        total_size,
        disk_stats_count: disk_count as u64,
        process_history_count: process_count as u64,
    })
}

pub async fn get_storage_efficiency(
    pool: &Pool<Sqlite>,
    db_path: &Path,
) -> Result<f64, Box<dyn std::error::Error>> {
    let stats = get_database_stats(pool, db_path).await?;
    
    // SatÄ±r baÅŸÄ±na ortalama byte
    if stats.disk_stats_count > 0 {
        let bytes_per_row = stats.total_size / stats.disk_stats_count;
        Ok(bytes_per_row as f64)
    } else {
        Ok(0.0)
    }
}
```

---

## ðŸ§ª Test Stratejisi

### Unit Tests

```rust
// File: src-tauri/src/db_cleanup.rs

#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_cleanup_removes_old_data() {
        // Setup: eski ve yeni veri ekle
        // Action: cleanup Ã§alÄ±ÅŸtÄ±r
        // Assert: sadece eski veri silindiÄŸini kontrol et
    }
    
    #[tokio::test]
    async fn test_cleanup_preserves_recent_data() {
        // Setup: son 30 gÃ¼n veri ekle
        // Action: cleanup Ã§alÄ±ÅŸtÄ±r
        // Assert: tÃ¼m veri korunduÄŸunu kontrol et
    }
    
    #[tokio::test]
    async fn test_retention_policy_default() {
        let policy = RetentionPolicy::default();
        assert_eq!(policy.keep_days, 30);
    }
}
```

### Integration Tests

```
âœ… Database initialization
âœ… Batch insert performance (1000 satÄ±r < 100ms)
âœ… Cleanup effectiveness (boyut azalmasÄ±)
âœ… Index performance (sorgu hÄ±zÄ±)
âœ… WAL checkpoint consistency
âœ… Archive mechanism (veri taÅŸÄ±ma)
âœ… PRAGMA settings application
```

### Performance Benchmarks

```
Ã–lÃ§Ã¼m NoktalarÄ±:
1. Insert: 1000 satÄ±rÄ±n eklenmesi (Ã¶ncesi/sonrasÄ±)
2. Query: Zaman aralÄ±ÄŸÄ± sorgusu (Ã¶ncesi/sonrasÄ±)
3. Size: VeritabanÄ± boyutu (cleanup Ã¶ncesi/sonrasÄ±)
4. Memory: Heap kullanÄ±mÄ± (Ã¶ncesi/sonrasÄ±)
5. CPU: Cleanup task CPU kullanÄ±mÄ±
```

---

## ðŸ“Š BaÅŸarÄ± Metrikleri

### Hedefler

| Metrik | Ã–ncesi | Hedef | BaÅŸarÄ± % |
|--------|--------|-------|----------|
| **DB Boyutu** | 400 MB (1 yÄ±l) | 120 MB (1 yÄ±l) | 70% azalma |
| **Cleanup SÃ¼resi** | N/A | < 10 saniye | - |
| **Query HÄ±zÄ±** | - | 2x hÄ±zlanma | 100% |
| **WAL Boyutu** | 50+ MB | 5 MB | 90% azalma |
| **Insert HÄ±zÄ±** | 1000 rows/1s | 2000 rows/1s | 100% |

### Monitoring Dashboard

```
ðŸ“ˆ Real-time Metrics:
â”œâ”€â”€ Database Size: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 285 MB
â”œâ”€â”€ Disk Stats Count: 31.5M rows
â”œâ”€â”€ Process History: 2.3K entries
â”œâ”€â”€ Last Cleanup: 12 hours ago
â”œâ”€â”€ WAL Size: 4.2 MB
â””â”€â”€ Avg Bytes/Row: 9.1 bytes
```

---

## ðŸ“ Uygulama Checklist

### Faz 1: Temel AltyapÄ±
- [ ] `db_cleanup.rs` oluÅŸtur
- [ ] `cleanup_old_data()` fonksiyonu yaz
- [ ] `RetentionPolicy` yapÄ±sÄ± tanÄ±mla
- [ ] Unit tests yaz

### Faz 2: Scheduled Tasks
- [ ] `scheduled_tasks.rs` oluÅŸtur
- [ ] Cleanup scheduler baÅŸlat
- [ ] ANALYZE scheduler baÅŸlat
- [ ] WAL checkpoint scheduler baÅŸlat
- [ ] `main.rs`'de schedulers'Ä± etkinleÅŸtir

### Faz 3: PRAGMA Optimizasyonu
- [ ] `db.rs`'de PRAGMA ayarlarÄ±nÄ± gÃ¼ncelle
- [ ] Yeni PRAGMA'larÄ± test et
- [ ] Performance test Ã§alÄ±ÅŸtÄ±r

### Faz 4: Ä°ndeks Stratejisi
- [ ] Yeni indeksleri `db.rs`'ye ekle
- [ ] Index oluÅŸturma test et
- [ ] Query performance Ã¶lÃ§

### Faz 5: Archive MekanizmasÄ± (Optional)
- [ ] `db_archive.rs` oluÅŸtur
- [ ] Archive tablosu oluÅŸtur
- [ ] Veri taÅŸÄ±ma test et
- [ ] Query optimization test et

### Faz 6: Batch Insert Optimizasyonu
- [ ] Transaction wrapper ekle
- [ ] Performance test Ã§alÄ±ÅŸtÄ±r
- [ ] Data consistency kontrol et

### Faz 7: Sampling MekanizmasÄ± (Optional)
- [ ] `db_sampling.rs` oluÅŸtur
- [ ] Sampling policy tanÄ±mla
- [ ] Insert logic'te kontrol ekle

### Faz 8: Database Stats
- [ ] `db_stats.rs` oluÅŸtur
- [ ] Size tracking fonksiyonlarÄ± yaz
- [ ] Frontend'e istatistik gÃ¶ster

### Faz 9: Migration
- [ ] Migration script oluÅŸtur
- [ ] Upgrade path tanÄ±mla
- [ ] Rollback plan hazÄ±rla

### Faz 10: Testing & Deployment
- [ ] TÃ¼m unit tests pass et
- [ ] Integration tests pass et
- [ ] Performance benchmarks Ã§alÄ±ÅŸtÄ±r
- [ ] Documentation gÃ¼ncelle
- [ ] Release notes yaz

---

## ðŸš€ BaÅŸlangÄ±Ã§ AdÄ±mlarÄ±

### GÃ¼n 1: Temel AltyapÄ±

```bash
# 1. db_cleanup.rs oluÅŸtur
# 2. cleanup_old_data() yaz
# 3. RetentionPolicy tanÄ±mla
# 4. Unit tests yaz
# 5. Tests yeÅŸil oldu mu kontrol et
```

### GÃ¼n 2: Schedulers

```bash
# 1. scheduled_tasks.rs oluÅŸtur
# 2. 3 scheduler baÅŸlat
# 3. main.rs'de entegre et
# 4. Manual test et
```

### GÃ¼n 3: PRAGMA & Ä°ndeksler

```bash
# 1. db.rs'de PRAGMA'larÄ± gÃ¼ncelle
# 2. Yeni indeksleri ekle
# 3. Performance test Ã§alÄ±ÅŸtÄ±r
# 4. Database size kontrol et
```

### GÃ¼n 4: Advanced Optimizations

```bash
# 1. Archive mekanizmasÄ± (optional)
# 2. Batch insert transaction wrapper
# 3. Database stats tracking
```

### GÃ¼n 5: Testing & Cleanup

```bash
# 1. TÃ¼m tests Ã§alÄ±ÅŸtÄ±r
# 2. Documentation gÃ¼ncelle
# 3. Release iÃ§in hazÄ±rla
```

---

## ðŸ“š Ä°lgili Dosyalar

### DeÄŸiÅŸtirilecek Dosyalar
- `src-tauri/src/db.rs` - PRAGMA, indeksler, batch insert
- `src-tauri/src/main.rs` - Scheduled tasks baÅŸlatma

### OluÅŸturulacak Dosyalar
- `src-tauri/src/db_cleanup.rs` - Cleanup fonksiyonlarÄ±
- `src-tauri/src/scheduled_tasks.rs` - Background schedulers
- `src-tauri/src/db_stats.rs` - Size tracking
- `src-tauri/src/db_archive.rs` - Archive mekanizmasÄ± (opsiyonel)
- `src-tauri/src/db_sampling.rs` - Sampling (opsiyonel)

### Test DosyalarÄ±
- `src-tauri/tests/db_cleanup_tests.rs`
- `src-tauri/tests/performance_tests.rs`

---

## ðŸ’¡ Ä°puÃ§larÄ± ve Best Practices

### GÃ¼venlik
âœ… Transaction'lar kullan (veri kaybÄ±nÄ± Ã¶nle)
âœ… Backup al (production cleanup Ã¶ncesi)
âœ… Gradual cleanup (tÃ¼m veriyi bir anda silme)

### Performance
âœ… Batch iÅŸlemler yap
âœ… Index oluÅŸtur (ama fazla olmadÄ±ÄŸÄ±ndan emin ol)
âœ… ANALYZE dÃ¼zenli Ã§alÄ±ÅŸtÄ±r
âœ… Scheduler'larÄ± yÃ¼ksÃ¼k yÃ¼kÃ¼n saatlerinde Ã§alÄ±ÅŸtÄ±r

### Monitoring
âœ… Cleanup sonuÃ§larÄ±nÄ± log'la
âœ… Database size takip et
âœ… Query slow log kaydÄ±nÄ± tut
âœ… Cleanup hata oranÄ±nÄ± takip et

### Documentation
âœ… Cleanup policies'i dokÃ¼mante et
âœ… Configuration seÃ§enekleri aÃ§Ä±kla
âœ… Troubleshooting guide yaz

---

## ðŸ“ž Sorular & Cevaplar

**S: Ne kadar veri tutmalÄ±yÄ±m?**  
C: VarsayÄ±lan 30 gÃ¼n, ama kullanÄ±cÄ± ayarlarla deÄŸiÅŸtirebilir.

**S: Archive mekanizmasÄ± gerekli mi?**  
C: HayÄ±r opsiyonel. Eski verileri sorgulamaya ihtiyaÃ§ varsa ekle.

**S: Sampling ne zaman kullanmalÄ±?**  
C: Disk I/O Ã§ok yÃ¼ksekse (30+ sec Ã¶rnekleme) ekle.

**S: Production'da cleanup yapabilir miyim?**  
C: Evet, PASSIVE WAL checkpoint ve background scheduler'Ä± kullan.

**S: Veri kaybÄ± riski var mÄ±?**  
C: HayÄ±r, transaction'lar ve retention policy'ler bunu engeller.

---

## ðŸŽ¯ SonuÃ§

Bu roadmap'Ä± takip ederek:
- ðŸ“‰ VeritabanÄ± boyutu %60-70 azalacak
- âš¡ Query performansÄ± 2x hÄ±zlanacak
- ðŸ”„ WAL dosyalarÄ± otomatik yÃ¶netilecek
- ðŸ“Š Veri depolama verimliliÄŸi artacak
- ðŸ›¡ï¸ Veri tutarlÄ±lÄ±ÄŸÄ± korunacak

**Tahmini Zaman:** 5-7 gÃ¼n (tam uygulama)

---

**Son GÃ¼ncelleme:** 28 AralÄ±k 2025  
**Versiyon:** 1.0
